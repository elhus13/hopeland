import uuid
import streamlit as st
import anthropic
import openai
from pinecone import Pinecone
import time
import base64
import docx # ì›Œë“œ íŒŒì¼ìš©
import io
from PIL import Image # ì´ë¯¸ì§€ ì²˜ë¦¬ìš©

# 1. ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="NDTC Team HQ", page_icon="ğŸ™ï¸", layout="wide")

# ==========================================
# [ë³´ì•ˆ] íŒ€ì› ë¡œê·¸ì¸ ì‹œìŠ¤í…œ
# ==========================================
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
    st.session_state.user_id = ""

def login():
    st.title("ğŸ”’ NDTC ë””ì§€í„¸ ë³¸ë¶€ (Hopeland)")
    st.write("ê´€ê³„ì ì™¸ ì¶œì…ê¸ˆì§€")
    
    with st.form("login_form"):
        col1, col2 = st.columns(2)
        with col1:
            user_id = st.text_input("ì•„ì´ë”” (ID)")
        with col2:
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸ (PW)", type="password")
        
        submitted = st.form_submit_button("ì¶œê·¼í•˜ê¸°")
        
        if submitted:
            # Secretsì—ì„œ ë¹„ë°€ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
            valid_users = st.secrets.get("passwords", {"admin": "1234", "team": "ndtc2026"})
            
            if user_id in valid_users and valid_users[user_id] == password:
                st.session_state.logged_in = True
                st.session_state.user_id = user_id
                st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {user_id}ë‹˜!")
                time.sleep(0.5)
                st.rerun()
            else:
                st.error("ğŸš« ì ‘ê·¼ ìŠ¹ì¸ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")

if not st.session_state.logged_in:
    login()
    st.stop()

# ==========================================
# [ë©”ì¸] ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# ==========================================
st.sidebar.success(f"ğŸ‘¤ ì ‘ì†ì: {st.session_state.user_id}")
st.title("ğŸ™ï¸ NDTC ë””ì§€í„¸ ë³¸ë¶€ (Hopeland)")
st.caption("AI & Blockchain ê¸°ë°˜ ë¬´ë”œëŸ¬ ìœ í†µ í˜ì‹  í”Œë«í¼")

# API í‚¤ ë¡œë“œ
try:
    anthropic_key = st.secrets["ANTHROPIC_API_KEY"]
    pinecone_key = st.secrets["PINECONE_API_KEY"] # DBìš©
    openai_key = st.secrets["OPENAI_API_KEY"] # ì„ë² ë”© ë° ë¹„ì „ìš©
except:
    st.error("âš ï¸ API í‚¤ ì„¤ì • ì˜¤ë¥˜: Secretsì— í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
client = anthropic.Anthropic(api_key=anthropic_key)
openai.api_key = openai_key
pc = Pinecone(api_key=pinecone_key)
index = pc.Index("ndtc-memory") # ìš°ë¦¬ê°€ ë§Œë“  ì¸ë±ìŠ¤ ì´ë¦„

# ë©”ë‰´ êµ¬ì„±
menu = st.sidebar.radio("ì—…ë¬´ ì„ íƒ", ["AI ì „ëµ ë¹„ì„œ (Chat)", "ì§€ì‹ ë„ì„œê´€ (ìë£Œ ì €ì¥)", "ëŒ€ì‹œë³´ë“œ"])

# ------------------------------------------
# 1. AI ì „ëµ ë¹„ì„œ (ì—˜íˆ¬ë¥´) - RAG ì ìš©
# ------------------------------------------
if menu == "AI ì „ëµ ë¹„ì„œ (Chat)":
    st.header("ğŸ¤– NDTC ìˆ˜ì„ ì „ëµê°€ 'ì—˜íˆ¬ë¥´'")
    
    # ì—˜í›„ìŠ¤ë‹˜ì˜ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ìœ ì§€
    system_context = """
    ë‹¹ì‹ ì€ 'NDTC(No Dealer trading city Center)'ì˜ ìˆ˜ì„ AI ì „ëµê°€ì´ì, ì—˜í›„ìŠ¤ë‹˜ì˜ ê°œì¸ ë¹„ì„œ 'ì—˜íˆ¬ë¥´'ì…ë‹ˆë‹¤.

    [ìš°ë¦¬ì˜ í•µì‹¬ ì‚¬ì—… (Core Business)]
    1. í”„ë¡œì íŠ¸ëª…: ë¦¬í”Œ(XRP) ê¸°ë°˜ ê¸€ë¡œë²Œ ìœ í†µ ë„ì‹œ ê±´ì„¤ ë° í”Œë«í¼ êµ¬ì¶•.
    2. ëª©í‘œ: ë¸”ë¡ì²´ì¸ê³¼ AI ê¸°ìˆ ì„ í™œìš©í•œ ë¬¼ë¥˜/ìœ í†µ í˜ì‹  ë„ì‹œ ì„¤ê³„.
    3. í•µì‹¬ ê¸°ìˆ : XRP Ledger(ë¦¬í”Œ ì›ì¥), ìì²´ í† í°(ìœ í‹¸ë¦¬í‹°)ë°œí–‰ ë° ìƒì¥, RWA ë°œí–‰
    4. í˜„ì¬ ìƒíƒœ: ì´ ì‚¬ì—…ì„ í•˜ê¸° ìœ„í•œ 'í•™ìŠµ' ë° 'ê¸°íš' ë‹¨ê³„ì„.

    [ë‹¹ì‹ ì˜ ì—­í•  (Role)]
    1. êµìœ¡ì(Tutor): ê¸°ìˆ  ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•œë‹¤.
    2. ë¶„ì„ê°€(Analyst): ì—…ë¡œë“œëœ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì ìš©ì ì„ ì œì•ˆí•œë‹¤.
    3. íŒŒíŠ¸ë„ˆ(Partner): ë¬´ì¡°ê±´ì  ì‘ì›ë³´ë‹¤ ê°ê´€ì ì¸ ë¶„ë³„ì„ ì œê³µí•œë‹¤.

    [ëŒ€í™” ê·œì¹™]
    - [ì°¸ê³ ìë£Œ]ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìµœìš°ì„ ìœ¼ë¡œ ë¶„ì„ ê·¼ê±°ë¡œ ì‚¼ëŠ”ë‹¤.
    - ì¤‘ê¸‰ ì´ìƒì˜ ì˜ì–´ ë‹¨ì–´ëŠ” ëœ»ê³¼ ë°œìŒì„ í•œê¸€ë¡œ ë³‘ê¸°í•œë‹¤.
    - ë‹µë³€ì€ í•­ìƒ ì •ì¤‘í•˜ê³  ë…¼ë¦¬ì ì´ì–´ì•¼ í•œë‹¤.
    """

    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì—˜íˆ¬ë¥´ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì–´ë–¤ ì „ëµì„ ë…¼ì˜í• ê¹Œìš”?"}]

    # ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸í•˜ê±°ë‚˜ ëª…ë ¹ì„ ë‚´ë ¤ì£¼ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").markdown(prompt)

        # 1) ì§€ì‹ ë„ì„œê´€ ê²€ìƒ‰ (RAG)
        knowledge_text = ""
        try:
            # ì§ˆë¬¸ì„ ìˆ«ìë¡œ ë³€í™˜ (Embedding)
            q_resp = openai.embeddings.create(input=prompt, model="text-embedding-3-small")
            q_vector = q_resp.data[0].embedding
            
            # Pineconeì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            search_res = index.query(vector=q_vector, top_k=3, include_metadata=True)
            
            # ê²€ìƒ‰ëœ ë‚´ìš© ì •ë¦¬
            found_docs = []
            for match in search_res['matches']:
                if match['score'] > 0.7: # ìœ ì‚¬ë„ê°€ 70% ì´ìƒì¸ ê²ƒë§Œ ì°¸ê³ 
                    found_docs.append(f"- {match['metadata']['filename']}: {match['metadata']['text']}")
            
            if found_docs:
                knowledge_text = "\n".join(found_docs)
                
        except Exception as e:
            # ê²€ìƒ‰ ì‹¤íŒ¨í•´ë„ ëŒ€í™”ëŠ” ì´ì–´ê°€ë„ë¡ í•¨
            pass

        # 2) ì—˜íˆ¬ë¥´ì—ê²Œ ì§ˆë¬¸ ì „ë‹¬ (ì§€ì‹ í¬í•¨)
        final_prompt = f"""
        {prompt}
        
        [ì°¸ê³ í•  ìš°ë¦¬ íŒ€ ë‚´ë¶€ ìë£Œ]
        {knowledge_text if knowledge_text else "ê´€ë ¨ëœ ë‚´ë¶€ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."}
        """

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            try:
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=4000,
                    system=system_context,
                    messages=[{"role": m["role"], "content": final_prompt if m["role"] == "user" and m["content"] == prompt else m["content"]} for m in st.session_state.messages]
                )
                answer = response.content[0].text
                
                # ì¶œì²˜ í‘œì‹œ
                if knowledge_text:
                    answer += "\n\n---\nğŸ“š **ì°¸ê³ í•œ ë‚´ë¶€ ìë£Œ:**\n" + "\n".join([f"- {m['metadata']['filename']}" for m in search_res['matches'] if m['score'] > 0.7])
                
                message_placeholder.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ------------------------------------------
# 2. ì§€ì‹ ë„ì„œê´€ (ìë£Œ ì—…ë¡œë“œ)
# ------------------------------------------
elif menu == "ì§€ì‹ ë„ì„œê´€ (ìë£Œ ì €ì¥)":
    st.header("ğŸ“š NDTC ì§€ì‹ ì €ì¥ì†Œ")
    st.info("íŒ€ì›ë“¤ì´ ê°€ì§„ PDF, ì›Œë“œ, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ íŒŒì¼ì„ ì—¬ê¸°ì— ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    with st.form("upload_form"):
        # [ê¸°ëŠ¥ ì¶”ê°€] docx, png, jpg ì§€ì›
        uploaded_file = st.file_uploader("íŒŒì¼ ì„ íƒ", type=["pdf", "txt", "docx", "png", "jpg", "jpeg"])
        category = st.selectbox("ìë£Œ ë¶„ë¥˜", ["ì‹œì¥ì¡°ì‚¬", "ê¸°ìˆ ë¬¸ì„œ", "ê¸°íšì•ˆ", "íšŒì˜ë¡", "í˜„ì¥ì‚¬ì§„"])
        saved = st.form_submit_button("ğŸ’¾ ë„ì„œê´€ì— ì €ì¥í•˜ê¸°")
        
        if saved and uploaded_file:
            with st.spinner("ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§
                    raw_text = ""
                    file_ext = uploaded_file.name.split('.')[-1].lower()
                    
                    # [A] ë¬¸ì„œ íŒŒì¼ ì²˜ë¦¬
                    if file_ext == "pdf":
                        import PyPDF2
                        reader = PyPDF2.PdfReader(uploaded_file)
                        for page in reader.pages:
                            raw_text += page.extract_text()
                    
                    elif file_ext == "docx":
                        doc = docx.Document(uploaded_file)
                        raw_text = "\n".join([p.text for p in doc.paragraphs])
                    
                    elif file_ext == "txt":
                        raw_text = uploaded_file.read().decode("utf-8")

                    # [B] ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (GPT-4o Vision)
                    elif file_ext in ["png", "jpg", "jpeg"]:
                         # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
                        img_bytes = uploaded_file.getvalue()
                        b64_img = base64.b64encode(img_bytes).decode('utf-8')
                        
                        # OpenAI Visionì—ê²Œ ì„¤ëª… ìš”ì²­
                        vision_resp = openai.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {
                                    "role": "user",
                                    "content": [
                                        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ê°€ ë‹´ê³  ìˆëŠ” ë‚´ìš©ì„ ìƒì„¸íˆ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…í•´ì¤˜."},
                                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}}
                                    ]
                                }
                            ]
                        )
                        raw_text = vision_resp.choices[0].message.content
                        st.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ë‚´ìš©: {raw_text[:100]}...")
                    
                    # 3) ì„ë² ë”© & ì €ì¥ (ê³µí†µ)
                    if raw_text:
                       emb_resp = openai.embeddings.create(
                           input=raw_text[:8000],
                           model="text-embedding-3-small"
                       )
                      vector = emb_resp.data[0].embedding

                      doc_id = str(uuid.uuid4())  # ğŸŸ© í•µì‹¬: í•œê¸€ íŒŒì¼ëª… ëŒ€ì‹  ì•ˆì „í•œ ID ì‚¬ìš©

                      index.upsert([
                         (doc_id, vector, {
                           "uploader": st.session_state.user_id,
                           "filename": uploaded_file.name,   # íŒŒì¼ëª…ì€ metadataì— ë³´ê´€
                           "category": category,
                           "text": raw_text[:2000]
                       })
                   ])

                   st.success("âœ… ì €ì¥ ì™„ë£Œ! ì´ì œ ì—˜íˆ¬ë¥´ê°€ ì´ ë‚´ìš©ì„ ê¸°ì–µí•©ë‹ˆë‹¤.")
             else:
               st.warning("íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
  
                        
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# ------------------------------------------
# 3. ëŒ€ì‹œë³´ë“œ
# ------------------------------------------
elif menu == "ëŒ€ì‹œë³´ë“œ":
    st.header("ğŸ“Š NDTC í”„ë¡œì íŠ¸ í˜„í™©")
    st.write("íŒ€ì›ë“¤ê³¼ ê³µìœ í•  ê³µì§€ì‚¬í•­ì´ë‚˜ í˜„í™©íŒì…ë‹ˆë‹¤.")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("í˜„ì¬ ë‹¨ê³„", "Phase 1", "ê¸°ë°˜ êµ¬ì¶•")
    col2.metric("ì§€ì‹ ë°ì´í„°", "Ready", "Pinecone ì—°ë™ë¨")
    col3.metric("íŒ€ì›", "5ëª…", "All Active")
